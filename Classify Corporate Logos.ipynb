{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch-related imports\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import DataLoaderIter\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, RandomRotation, RandomResizedCrop, ToTensor\n",
    "\n",
    "# helper functions\n",
    "from os.path import join\n",
    "\n",
    "# full libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set random seeds\n",
    "seed = 22\n",
    "np.random.seed(seed)\n",
    "_ = torch.random.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlickrDataset(Dataset):\n",
    "    def __init__(self, annotations_path, images_path, transform):\n",
    "        self.images_path = images_path\n",
    "        self.df = pd.read_csv(annotations_path,\n",
    "                              sep=\" \",\n",
    "                              header=None,\n",
    "                              names=[\"file_name\", \"logo\", 1, 2, 3, 4, 5, 6])\n",
    "        self.labels_dict = {label: idx for idx, label in enumerate(self.df[\"logo\"].unique())}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index, :]\n",
    "        fpath = join(self.images_path, row[\"file_name\"])\n",
    "        im = PIL.Image.open(fpath)\n",
    "        return self.transform(im), self.labels_dict[row[\"logo\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickrData = FlickrDataset(join(\"data\", \"flickr_logos_27_dataset\", \"flickr_logos_27_dataset_training_set_annotation.txt\"),\n",
    "                          join(\"data\", \"flickr_logos_27_dataset\", \"flickr_logos_27_dataset_images\"),\n",
    "                          transform=Compose([\n",
    "                              RandomRotation(10),\n",
    "                              RandomResizedCrop(256),\n",
    "                              ToTensor()\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "flickrLoader = DataLoader(flickrData,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyClassifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        print(self.layer1)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        print(self.layer2)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(900, 27, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        print(self.linear1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.linear1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d (3, 4, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): Conv2d (4, 4, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=900, out_features=27)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "classifier = MyClassifier()\n",
    "learning_rate = 0.0001\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Iter [100/283] Loss: 3.3995\n",
      "Epoch [1/100], Iter [200/283] Loss: 3.1441\n",
      "Epoch [2/100], Iter [100/283] Loss: 3.2050\n",
      "Epoch [2/100], Iter [200/283] Loss: 3.2897\n",
      "Epoch [3/100], Iter [100/283] Loss: 2.9070\n",
      "Epoch [3/100], Iter [200/283] Loss: 3.0633\n",
      "Epoch [4/100], Iter [100/283] Loss: 2.7599\n",
      "Epoch [4/100], Iter [200/283] Loss: 2.8744\n",
      "Epoch [5/100], Iter [100/283] Loss: 3.0504\n",
      "Epoch [5/100], Iter [200/283] Loss: 2.9060\n",
      "Epoch [6/100], Iter [100/283] Loss: 2.5182\n",
      "Epoch [6/100], Iter [200/283] Loss: 2.9077\n",
      "Epoch [7/100], Iter [100/283] Loss: 2.9936\n",
      "Epoch [7/100], Iter [200/283] Loss: 3.0463\n",
      "Epoch [8/100], Iter [100/283] Loss: 2.9636\n",
      "Epoch [8/100], Iter [200/283] Loss: 2.7774\n",
      "Epoch [9/100], Iter [100/283] Loss: 3.0437\n",
      "Epoch [9/100], Iter [200/283] Loss: 2.8595\n",
      "Epoch [10/100], Iter [100/283] Loss: 2.6458\n",
      "Epoch [10/100], Iter [200/283] Loss: 2.7322\n",
      "Epoch [11/100], Iter [100/283] Loss: 2.8958\n",
      "Epoch [11/100], Iter [200/283] Loss: 3.3333\n",
      "Epoch [12/100], Iter [100/283] Loss: 3.2802\n",
      "Epoch [12/100], Iter [200/283] Loss: 2.3509\n",
      "Epoch [13/100], Iter [100/283] Loss: 2.4815\n",
      "Epoch [13/100], Iter [200/283] Loss: 2.5025\n",
      "Epoch [14/100], Iter [100/283] Loss: 2.7423\n",
      "Epoch [14/100], Iter [200/283] Loss: 2.3844\n",
      "Epoch [15/100], Iter [100/283] Loss: 2.4846\n",
      "Epoch [15/100], Iter [200/283] Loss: 2.7223\n",
      "Epoch [16/100], Iter [100/283] Loss: 2.3563\n",
      "Epoch [16/100], Iter [200/283] Loss: 2.4887\n",
      "Epoch [17/100], Iter [100/283] Loss: 2.7060\n",
      "Epoch [17/100], Iter [200/283] Loss: 3.4003\n",
      "Epoch [18/100], Iter [100/283] Loss: 2.1662\n",
      "Epoch [18/100], Iter [200/283] Loss: 2.2897\n",
      "Epoch [19/100], Iter [100/283] Loss: 2.6145\n",
      "Epoch [19/100], Iter [200/283] Loss: 2.4065\n",
      "Epoch [20/100], Iter [100/283] Loss: 2.6504\n",
      "Epoch [20/100], Iter [200/283] Loss: 2.3843\n",
      "Epoch [21/100], Iter [100/283] Loss: 1.9831\n",
      "Epoch [21/100], Iter [200/283] Loss: 3.0065\n",
      "Epoch [22/100], Iter [100/283] Loss: 2.3485\n",
      "Epoch [22/100], Iter [200/283] Loss: 2.6439\n",
      "Epoch [23/100], Iter [100/283] Loss: 2.7927\n",
      "Epoch [23/100], Iter [200/283] Loss: 2.6403\n",
      "Epoch [24/100], Iter [100/283] Loss: 2.7926\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(DataLoaderIter(flickrLoader)):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(images)\n",
    "        l = loss(outputs, labels)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(flickrData)//batch_size, l.data[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
